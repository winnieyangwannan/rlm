{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b5e72f",
   "metadata": {},
   "source": [
    "#  Prompt Revision\n",
    "\n",
    "- This is offline setting for re-writing the whole prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66628fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "import rlm_log_utils\n",
    "importlib.reload(rlm_log_utils)\n",
    "from rlm_log_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b4e70",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "Load the log file and extract key information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754fc72",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f328b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 iterations\n"
     ]
    }
   ],
   "source": [
    "LOG_PATH = \"/checkpoint/maui_sft/winnieyangwn/rlm_dumps/gpt-5_common_invalid_errors_514_2026-02-06_02-00-10_6a06754f.jsonl\"\n",
    "# Load the log - first entry is metadata, rest are iterations\n",
    "entries = load_rlm_log(LOG_PATH)\n",
    "metadata = entries[0]\n",
    "iterations = entries[1:]\n",
    "\n",
    "print(f\"Loaded {len(iterations)} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a88249",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f17c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== METADATA ===\n",
      "type: metadata\n",
      "timestamp: 2026-02-06T02:00:10.403545\n",
      "root_model: gpt-5\n",
      "max_depth: 1\n",
      "max_iterations: 10\n",
      "backend: azure_openai\n",
      "environment_type: local\n",
      "environment_kwargs: {'setup_code': \"\\nimport pandas as pd\\ncontext = pd.read_json('/checkpoint/maui_sft/winnieyangwn/amaia_dumps/514/trajectories/514_metadata.jsonl', lines=True)\\n\"}\n",
      "other_backends: None\n"
     ]
    }
   ],
   "source": [
    "# View metadata\n",
    "print(\"=== METADATA ===\")\n",
    "for k, v in metadata.items():\n",
    "    if k != \"backend_kwargs\":\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba91dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp-based runtime: 80.52s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare with timestamp-based runtime\n",
    "runtime = get_total_runtime(entries)\n",
    "print(f\"Timestamp-based runtime: {runtime.total_seconds():.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5627fc3",
   "metadata": {},
   "source": [
    "# Final Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e39a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL ANSWER ===\n",
      "Top 5 most common evaluation error messages among invalid submissions (n=994):\n",
      "- \"Execution returned non-zero exit code\" — 595 (59.86%)\n",
      "- \"Chunked file copy failed: Download failed: Failed to extract file from container: Failed to read file from container: WARNING: Error changing the container working directory. Using '/' instead: chdir /home/winnieyangwn: no such file or directory\n",
      "/usr/bin/cat: /workspace/submission.csv: No such file or directory\n",
      "\" — 194 (19.52%)\n",
      "- \"Submission invalid! The attempt to grade the submission has resulted in the following error message:\n",
      "Error tokenizing data. C error: Expected 141 fields in line 3, saw 334\n",
      "\" — 40 (4.02%)\n",
      "- \"Execution timed out\" — 28 (2.82%)\n",
      "- \"\" (empty message) — 19 (1.91%)\n"
     ]
    }
   ],
   "source": [
    "# Get the final answer\n",
    "final_answer = get_final_answer(iterations)\n",
    "print(\"=== FINAL ANSWER ===\")\n",
    "print(final_answer if final_answer else \"No final answer found\")\n",
    "# print(f\"\\n(Total length: {len(final_answer) if final_answer else 0} chars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd0c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
