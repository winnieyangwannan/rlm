{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b0942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import zlib\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "\n",
    "sys.path.append('data/data_utils')\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320f4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 513\n",
    "file_path = f'/checkpoint/maui_sft/winnieyangwn/amaia_dumps/{run_id}/trajectories/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f86f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trj = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37360c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3774, 9)\n",
      "Columns: ['task_name', 'task_description', 'code', 'percentile', 'valid_submission', 'eval_error_message', 'eval_duration', 'rollout_duration', 'rollout']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_description</th>\n",
       "      <th>code</th>\n",
       "      <th>percentile</th>\n",
       "      <th>valid_submission</th>\n",
       "      <th>eval_error_message</th>\n",
       "      <th>eval_duration</th>\n",
       "      <th>rollout_duration</th>\n",
       "      <th>rollout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aerial-cactus-identification</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Description\\n...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Execution returned non-zero exit code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.208566</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aerial-cactus-identification</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Description\\n...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Execution returned non-zero exit code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.979062</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>import os\\nimport sys\\nimport math\\nimport csv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Execution returned non-zero exit code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.721609</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Execution returned non-zero exit code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.420535</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Execution returned non-zero exit code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.732197</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      task_name  \\\n",
       "0  aerial-cactus-identification   \n",
       "1  aerial-cactus-identification   \n",
       "2     denoising-dirty-documents   \n",
       "3     denoising-dirty-documents   \n",
       "4     denoising-dirty-documents   \n",
       "\n",
       "                                    task_description  \\\n",
       "0  # Overview\\n\\n## Overview\\n\\n### Description\\n...   \n",
       "1  # Overview\\n\\n## Overview\\n\\n### Description\\n...   \n",
       "2  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "3  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "4  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "\n",
       "                                                code  percentile  \\\n",
       "0  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "1  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "2  import os\\nimport sys\\nimport math\\nimport csv...         0.0   \n",
       "3  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "4  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "\n",
       "   valid_submission                     eval_error_message  eval_duration  \\\n",
       "0             False  Execution returned non-zero exit code            0.0   \n",
       "1             False  Execution returned non-zero exit code            0.0   \n",
       "2             False  Execution returned non-zero exit code            0.0   \n",
       "3             False  Execution returned non-zero exit code            0.0   \n",
       "4             False  Execution returned non-zero exit code            0.0   \n",
       "\n",
       "   rollout_duration                                            rollout  \n",
       "0        186.208566  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "1        188.979062  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "2        194.721609  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "3        197.420535  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "4        198.732197  [{'turn_id': 0, 'action': '', 'observation': '...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Flatten the dataframe\n",
    "df_flat = flatten_dataframe(df_trj)\n",
    "\n",
    "print(f\"Shape: {df_flat.shape}\")\n",
    "print(f\"Columns: {df_flat.columns.tolist()}\")\n",
    "df_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b38af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.20856591500342"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trj.iloc[0][\"rollouts\"][0][\"metrics\"][\"rollout/duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd5e6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/usr/bin/env python3\\nimport os\\nimport sys\\nimport time\\nimport json\\nimport math\\nimport random\\nimport argparse\\nfrom dataclasses import dataclass\\n\\n# Attempt to import required packages; install if missing\\n\\ndef ensure_imports():\\n    import importlib\\n    need = []\\n    for pkg in [\\n        (\\'torch\\', \\'torch\\'),\\n        (\\'torchvision\\', \\'torchvision\\'),\\n        (\\'sklearn\\', \\'sklearn\\'),\\n        (\\'pandas\\', \\'pandas\\'),\\n        (\\'numpy\\', \\'numpy\\'),\\n        (\\'PIL\\', \\'PIL\\'),\\n    ]:\\n        try:\\n            importlib.import_module(pkg[0])\\n        except Exception:\\n            need.append(pkg[1])\\n    if need:\\n        print(f\"[setup] Installing missing packages: {need}\")\\n        import subprocess\\n        subprocess.check_call([sys.executable, \\'-m\\', \\'pip\\', \\'install\\', \\'--no-input\\'] + need)\\n\\nensure_imports()\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom PIL import Image\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom torch.utils.data import Dataset, DataLoader\\nimport torchvision.transforms as T\\nimport torchvision.models as models\\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\\nfrom sklearn.metrics import roc_auc_score\\n\\n# Reproducibility\\n\\ndef set_seed(seed=42):\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n    torch.backends.cudnn.deterministic = False\\n    torch.backends.cudnn.benchmark = True\\n\\n# Dataset\\n\\nclass CactusDataset(Dataset):\\n    def __init__(self, df, img_dir, transform=None, is_test=False):\\n        self.df = df.reset_index(drop=True)\\n        self.img_dir = img_dir\\n        self.transform = transform\\n        self.is_test = is_test\\n    def __len__(self):\\n        return len(self.df)\\n    def __getitem__(self, idx):\\n        row = self.df.iloc[idx]\\n        img_path = os.path.join(self.img_dir, row[\\'id\\'])\\n        with Image.open(img_path) as im:\\n            im = im.convert(\\'RGB\\')\\n            if self.transform:\\n                im = self.transform(im)\\n        if self.is_test:\\n            return im, row[\\'id\\']\\n        label = float(row[\\'has_cactus\\'])\\n        return im, torch.tensor([label], dtype=torch.float32)\\n\\n# Model builder\\n\\ndef build_model(num_classes=1):\\n    # Use ResNet18 pretrained, adapt to binary output\\n    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\\n    in_features = model.fc.in_features\\n    model.fc = nn.Linear(in_features, num_classes)\\n    return model\\n\\n# Train and evaluate\\n\\n@dataclass\\nclass TrainConfig:\\n    img_size: int = 96\\n    batch_size: int = 256\\n    epochs: int = 10\\n    lr: float = 1e-3\\n    weight_decay: float = 1e-4\\n    val_split: float = 0.1\\n    num_workers: int = 4\\n    amp: bool = True\\n    patience: int = 3\\n\\n\\ndef get_transforms(img_size):\\n    mean = [0.485, 0.456, 0.406]\\n    std = [0.229, 0.224, 0.225]\\n    train_tf = T.Compose([\\n        T.Resize((img_size, img_size)),\\n        T.RandomHorizontalFlip(),\\n        T.RandomVerticalFlip(),\\n        T.RandomRotation(20),\\n        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\\n        T.ToTensor(),\\n        T.Normalize(mean, std),\\n    ])\\n    val_tf = T.Compose([\\n        T.Resize((img_size, img_size)),\\n        T.ToTensor(),\\n        T.Normalize(mean, std),\\n    ])\\n    return train_tf, val_tf\\n\\n\\ndef train_one_epoch(model, loader, optimizer, scaler, device):\\n    model.train()\\n    loss_meter = 0.0\\n    n = 0\\n    for images, targets in loader:\\n        images = images.to(device)\\n        targets = targets.to(device)\\n        optimizer.zero_grad(set_to_none=True)\\n        if scaler is not None:\\n            with torch.cuda.amp.autocast():\\n                logits = model(images)\\n                loss = F.binary_cross_entropy_with_logits(logits.view(-1), targets.view(-1))\\n            scaler.scale(loss).backward()\\n            scaler.step(optimizer)\\n            scaler.update()\\n        else:\\n            logits = model(images)\\n            loss = F.binary_cross_entropy_with_logits(logits.view(-1), targets.view(-1))\\n            loss.backward()\\n            optimizer.step()\\n        batch = images.size(0)\\n        loss_meter += loss.item() * batch\\n        n += batch\\n    return loss_meter / max(n, 1)\\n\\n\\ndef evaluate(model, loader, device):\\n    model.eval()\\n    loss_meter = 0.0\\n    n = 0\\n    all_probs = []\\n    all_targets = []\\n    with torch.no_grad():\\n        for images, targets in loader:\\n            images = images.to(device)\\n            targets = targets.to(device)\\n            logits = model(images)\\n            loss = F.binary_cross_entropy_with_logits(logits.view(-1), targets.view(-1))\\n            probs = torch.sigmoid(logits.view(-1))\\n            all_probs.append(probs.cpu().numpy())\\n            all_targets.append(targets.view(-1).cpu().numpy())\\n            batch = images.size(0)\\n            loss_meter += loss.item() * batch\\n            n += batch\\n    all_probs = np.concatenate(all_probs) if all_probs else np.array([])\\n    all_targets = np.concatenate(all_targets) if all_targets else np.array([])\\n    auc = roc_auc_score(all_targets, all_probs) if len(all_targets) > 0 and len(np.unique(all_targets)) > 1 else float(\\'nan\\')\\n    return loss_meter / max(n, 1), auc\\n\\n\\ndef train_model(train_df, cfg: TrainConfig, data_root, fast_dev=False):\\n    device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n    print(f\"[info] Using device: {device}\")\\n    train_tf, val_tf = get_transforms(cfg.img_size)\\n\\n    # Split train/val\\n    train_df_, val_df_ = train_test_split(train_df, test_size=cfg.val_split, random_state=42, stratify=train_df[\\'has_cactus\\'])\\n\\n    if fast_dev:\\n        # Use small subset for quick validation\\n        train_df_ = train_df_.sample(n=min(1024, len(train_df_)), random_state=42)\\n        val_df_ = val_df_.sample(n=min(256, len(val_df_)), random_state=42)\\n        print(f\"[dev] Using subset: train {len(train_df_)} val {len(val_df_)}\")\\n\\n    train_ds = CactusDataset(train_df_, img_dir=os.path.join(data_root, \\'train\\'), transform=train_tf, is_test=False)\\n    val_ds = CactusDataset(val_df_, img_dir=os.path.join(data_root, \\'train\\'), transform=val_tf, is_test=False)\\n\\n    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\\n    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\\n\\n    model = build_model(num_classes=1)\\n    model.to(device)\\n\\n    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\\n    scaler = torch.cuda.amp.GradScaler() if (cfg.amp and device.type == \\'cuda\\') else None\\n\\n    best_auc = -1.0\\n    best_epoch = -1\\n    best_path = \\'/workspace/best_model.pth\\'\\n    es_counter = 0\\n\\n    for epoch in range(cfg.epochs):\\n        t0 = time.time()\\n        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, device)\\n        val_loss, val_auc = evaluate(model, val_loader, device)\\n        scheduler.step()\\n        dt = time.time() - t0\\n        print(f\"[epoch {epoch+1}/{cfg.epochs}] train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_auc={val_auc:.4f} time={dt:.1f}s\")\\n        if not math.isnan(val_auc) and val_auc > best_auc:\\n            best_auc = val_auc\\n            best_epoch = epoch\\n            torch.save({\\'model\\': model.state_dict(), \\'cfg\\': cfg.__dict__}, best_path)\\n            es_counter = 0\\n            print(f\"[checkpoint] Saved best model with AUC={best_auc:.4f} at epoch {epoch+1}\")\\n        else:\\n            es_counter += 1\\n        if es_counter >= cfg.patience:\\n            print(f\"[early_stop] No improvement for {cfg.patience} epochs. Stopping.\")\\n            break\\n\\n    # Load best\\n    if os.path.exists(best_path):\\n        ckpt = torch.load(best_path, map_location=device)\\n        model.load_state_dict(ckpt[\\'model\\'])\\n        print(f\"[load] Loaded best checkpoint from epoch {best_epoch+1} with AUC={best_auc:.4f}\")\\n    else:\\n        print(\"[warn] Best checkpoint not found; using current model\")\\n    return model, val_loader\\n\\n\\ndef infer(model, test_df, cfg: TrainConfig, data_root):\\n    device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n    _, val_tf = get_transforms(cfg.img_size)\\n    test_ds = CactusDataset(test_df, img_dir=os.path.join(data_root, \\'test\\'), transform=val_tf, is_test=True)\\n    test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\\n    model.eval()\\n    model.to(device)\\n    ids = []\\n    probs = []\\n    with torch.no_grad():\\n        for images, img_ids in test_loader:\\n            images = images.to(device)\\n            logits = model(images)\\n            p = torch.sigmoid(logits.view(-1)).cpu().numpy()\\n            ids.extend(list(img_ids))\\n            probs.extend(list(p))\\n    return ids, probs\\n\\n\\ndef main():\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\\'--data_root\\', type=str, default=\\'/root/data\\')\\n    parser.add_argument(\\'--output\\', type=str, default=\\'/workspace/submission.csv\\')\\n    parser.add_argument(\\'--fast_dev\\', action=\\'store_true\\')\\n    args = parser.parse_args()\\n\\n    set_seed(42)\\n\\n    # Load CSVs\\n    train_csv = os.path.join(args.data_root, \\'train.csv\\')\\n    sample_csv = os.path.join(args.data_root, \\'sample_submission.csv\\')\\n    train_df = pd.read_csv(train_csv)\\n    # Ensure correct dtypes\\n    train_df[\\'has_cactus\\'] = train_df[\\'has_cactus\\'].astype(int)\\n\\n    # Decide training config\\n    fast_dev_env = os.environ.get(\\'FAST_DEV_RUN\\', \\'0\\') == \\'1\\'\\n    fast_mode = args.fast_dev or fast_dev_env\\n    cfg = TrainConfig()\\n    if fast_mode:\\n        cfg.epochs = 2\\n        cfg.batch_size = 128\\n        cfg.num_workers = 2\\n        print(\\'[mode] FAST_DEV_RUN enabled for quick validation\\')\\n\\n    # Train\\n    model, val_loader = train_model(train_df, cfg, args.data_root, fast_dev=fast_mode)\\n\\n    # Inference\\n    # Respect sample submission order if available\\n    if os.path.exists(sample_csv):\\n        test_df = pd.read_csv(sample_csv)\\n        test_df = test_df[[\\'id\\']]\\n        print(f\"[info] Using sample_submission order with {len(test_df)} rows\")\\n    else:\\n        # List test dir\\n        test_dir = os.path.join(args.data_root, \\'test\\')\\n        ids = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(\\'.jpg\\')])\\n        test_df = pd.DataFrame({\\'id\\': ids})\\n        print(f\"[info] Using directory listing order with {len(test_df)} rows\")\\n\\n    ids, probs = infer(model, test_df, cfg, args.data_root)\\n\\n    # Write submission\\n    os.makedirs(os.path.dirname(args.output), exist_ok=True)\\n    sub_df = pd.DataFrame({\\'id\\': ids, \\'has_cactus\\': probs})\\n    sub_df.to_csv(args.output, index=False)\\n    print(f\"[done] Wrote submission to {args.output} with {len(sub_df)} rows\")\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trj.iloc[0][\"rollouts\"][0][\"traj\"][\"transitions\"][-1][\"info\"][\"pred_solution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0a497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_timeout': False,\n",
       " 'parse_error': False,\n",
       " 'max_turns_reached': False,\n",
       " 'test_execution_error': True,\n",
       " 'container_creation_error': False,\n",
       " 'container_execution_error': False,\n",
       " 'model_call_error': False,\n",
       " 'model_output_empty_cmd': False,\n",
       " 'gpu_timeout': False,\n",
       " 'valid_submission': False,\n",
       " 'percentile': 0.0,\n",
       " 'gpu_execution_duration': 0.0,\n",
       " 'eval_error_message': 'Execution returned non-zero exit code',\n",
       " 'eval_error_output': 'SystemExit: 2\\nAn exception has occurred, use %tb to see the full traceback.\\n\\nSystemExit: 2\\n',\n",
       " 'pass': False,\n",
       " 'eval_outcome': 'fail',\n",
       " 'pred_solution_provided': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trj.iloc[0][\"rollouts\"][0][\"traj\"][\"transitions\"][-1][\"outcomes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4e65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19290d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3774, 9)\n",
      "Columns: ['task_name', 'task_description', 'code', 'percentile', 'valid_submission', 'eval_error_output', 'eval_duration', 'rollout_duration', 'rollout']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_description</th>\n",
       "      <th>code</th>\n",
       "      <th>percentile</th>\n",
       "      <th>valid_submission</th>\n",
       "      <th>eval_error_output</th>\n",
       "      <th>eval_duration</th>\n",
       "      <th>rollout_duration</th>\n",
       "      <th>rollout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aerial-cactus-identification</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Description\\n...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>SystemExit: 2\\nAn exception has occurred, use ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.208566</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aerial-cactus-identification</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Description\\n...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>SystemExit: 2\\nAn exception has occurred, use ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.979062</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>import os\\nimport sys\\nimport math\\nimport csv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>SystemExit: 2\\nAn exception has occurred, use ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.721609</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>SystemExit: 2\\nAn exception has occurred, use ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.420535</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denoising-dirty-documents</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\n[Optical Chara...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>SystemExit: 2\\nAn exception has occurred, use ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.732197</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      task_name  \\\n",
       "0  aerial-cactus-identification   \n",
       "1  aerial-cactus-identification   \n",
       "2     denoising-dirty-documents   \n",
       "3     denoising-dirty-documents   \n",
       "4     denoising-dirty-documents   \n",
       "\n",
       "                                    task_description  \\\n",
       "0  # Overview\\n\\n## Overview\\n\\n### Description\\n...   \n",
       "1  # Overview\\n\\n## Overview\\n\\n### Description\\n...   \n",
       "2  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "3  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "4  # Overview\\n\\n## Description\\n\\n[Optical Chara...   \n",
       "\n",
       "                                                code  percentile  \\\n",
       "0  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "1  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "2  import os\\nimport sys\\nimport math\\nimport csv...         0.0   \n",
       "3  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "4  #!/usr/bin/env python3\\nimport os\\nimport sys\\...         0.0   \n",
       "\n",
       "   valid_submission                                  eval_error_output  \\\n",
       "0             False  SystemExit: 2\\nAn exception has occurred, use ...   \n",
       "1             False  SystemExit: 2\\nAn exception has occurred, use ...   \n",
       "2             False  SystemExit: 2\\nAn exception has occurred, use ...   \n",
       "3             False  SystemExit: 2\\nAn exception has occurred, use ...   \n",
       "4             False  SystemExit: 2\\nAn exception has occurred, use ...   \n",
       "\n",
       "   eval_duration  rollout_duration  \\\n",
       "0            0.0        186.208566   \n",
       "1            0.0        188.979062   \n",
       "2            0.0        194.721609   \n",
       "3            0.0        197.420535   \n",
       "4            0.0        198.732197   \n",
       "\n",
       "                                             rollout  \n",
       "0  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "1  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "2  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "3  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "4  [{'turn_id': 0, 'action': '', 'observation': '...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the dataframe\n",
    "df_flat = flatten_dataframe(df_trj)\n",
    "\n",
    "print(f\"Shape: {df_flat.shape}\")\n",
    "print(f\"Columns: {df_flat.columns.tolist()}\")\n",
    "df_flat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ab197fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3774 rows to /checkpoint/maui_sft/winnieyangwn/amaia_dumps/513/trajectories/513_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "save_path = f'/checkpoint/maui_sft/winnieyangwn/amaia_dumps/{run_id}/trajectories/{run_id}_metadata.jsonl'\n",
    "\n",
    "# Save df_flat to jsonl\n",
    "df_flat.to_json(save_path, orient='records', lines=True)\n",
    "print(f\"Saved {len(df_flat)} rows to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204df1",
   "metadata": {},
   "source": [
    "# Data Structure Description\n",
    "\n",
    "The context is a list of dictionaries, where each dictionary represents one MLE Bench rollout (an agent's attempt to solve a machine learning task). There are 4,800 rollouts in total.\n",
    "\n",
    "Each rollout dictionary has the following fields:\n",
    "\n",
    "1. **\"task_name\"** (str): The unique identifier for the ML task (e.g., \"detecting-insults-in-social-commentary\")\n",
    "\n",
    "2. **\"task_description\"** (str): Full markdown description of the ML task including overview, evaluation criteria, and submission format\n",
    "\n",
    "3. **\"code\"** (str | None): The final Python code solution submitted by the agent\n",
    "\n",
    "4. **\"percentile\"** (float | None): Performance percentile (0-100) achieved by the submission. Higher is better. 100 means top performer.\n",
    "\n",
    "5. **\"valid_submission\"** (bool | None): Whether the agent produced a valid submission file\n",
    "\n",
    "6. **\"eval_error_message\"** (str | None): Evaluation result message - contains success info or error details\n",
    "\n",
    "7. **\"eval_duration\"** (float | None): GPU execution time in seconds for evaluation\n",
    "\n",
    "8. **\"rollout_duration\"** (float | None): Total time in seconds for the entire rollout\n",
    "\n",
    "9. **\"rollout\"** (list[dict]): The full conversation trajectory as a list of turns. Each turn has:\n",
    "   - \"turn_id\" (int): Turn number starting from 0\n",
    "   - \"action\" (str): The agent's action/response (typically bash commands in XML tags)\n",
    "   - \"observation\" (str): The environment's response/prompt to the agent\n",
    "\n",
    "## Example access patterns:\n",
    "```python\n",
    "# Get task name\n",
    "context[0][\"task_name\"]\n",
    "\n",
    "# Get percentile\n",
    "context[0][\"percentile\"]\n",
    "\n",
    "# Get number of turns\n",
    "len(context[0][\"rollout\"])\n",
    "\n",
    "# Get first action\n",
    "context[0][\"rollout\"][0][\"action\"]\n",
    "\n",
    "# Filter successful submissions\n",
    "[r for r in context if r[\"valid_submission\"] == True]\n",
    "\n",
    "# Filter by percentile\n",
    "[r for r in context if r[\"percentile\"] and r[\"percentile\"] >= 50]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cb64c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f6ba64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amaia-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
