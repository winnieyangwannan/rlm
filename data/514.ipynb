{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b0942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import zlib\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append('data/data_utils')\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320f4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_id = 514\n",
    "# file_path= f'/checkpoint/maui_sft/winnieyangwn/amaia_dumps/{run_id}/trajectories/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl.jsonl'\n",
    "file_path = f'/checkpoint/maui_sft/winnieyangwn/amaia_dumps/{run_id}/trajectories/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl/mle_bench_bashmle_bench_checkpoint_maui_sft_shared_kniu_datasets_mlebench_full_jsonl.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f86f2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_trj \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_json(file_path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_trj = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b38af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232.22987089073285"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trj.iloc[0][\"rollouts\"][0][\"metrics\"][\"rollout/duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5e6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport sys\\nimport time\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom scipy.sparse import hstack, csr_matrix\\n\\n# ---------------------------\\n# Utility: text preprocessing\\n# ---------------------------\\n\\ndef preprocess_text_series(texts: pd.Series) -> pd.Series:\\n    def clean_one(s):\\n        if not isinstance(s, str):\\n            return \"\"\\n        # Strip surrounding quotes if present\\n        if len(s) >= 2 and s[0] == \\'\"\\' and s[-1] == \\'\"\\':\\n            s = s[1:-1]\\n        # Heuristic: decode common backslash escapes if present\\n        try:\\n            if (\"\\\\\\\\x\" in s) or (\"\\\\\\\\u\" in s) or (\"\\\\\\\\n\" in s) or (\"\\\\\\\\t\" in s):\\n                # encode to bytes then decode unicode_escape to interpret escapes\\n                s = s.encode(\\'utf-8\\', errors=\\'ignore\\').decode(\\'unicode_escape\\', errors=\\'ignore\\')\\n        except Exception:\\n            pass\\n        # Normalize whitespace\\n        s = s.replace(\\'\\\\r\\', \\' \\').replace(\\'\\\\n\\', \\' \\').replace(\\'\\\\t\\', \\' \\')\\n        s = \\' \\'.join(s.split())\\n        return s\\n    return texts.fillna(\"\").apply(clean_one)\\n\\n\\ndef build_features(train_texts, test_texts):\\n    # Word-level TF-IDF\\n    word_vec = TfidfVectorizer(\\n        lowercase=True,\\n        strip_accents=\\'unicode\\',\\n        ngram_range=(1, 2),\\n        min_df=2,\\n        max_df=0.98,\\n        max_features=200000,\\n        sublinear_tf=True,\\n    )\\n    # Character-level TF-IDF inside word boundaries\\n    char_vec = TfidfVectorizer(\\n        analyzer=\\'char_wb\\',\\n        lowercase=True,\\n        strip_accents=\\'unicode\\',\\n        ngram_range=(3, 5),\\n        min_df=2,\\n        sublinear_tf=True,\\n    )\\n\\n    print(\\'[INFO] Fitting word TF-IDF on training texts...\\')\\n    Xw_tr = word_vec.fit_transform(train_texts)\\n    print(f\\'[INFO] Word TF-IDF train shape: {Xw_tr.shape}\\')\\n    print(\\'[INFO] Transforming test texts with word TF-IDF...\\')\\n    Xw_te = word_vec.transform(test_texts)\\n\\n    print(\\'[INFO] Fitting char TF-IDF on training texts...\\')\\n    Xc_tr = char_vec.fit_transform(train_texts)\\n    print(f\\'[INFO] Char TF-IDF train shape: {Xc_tr.shape}\\')\\n    print(\\'[INFO] Transforming test texts with char TF-IDF...\\')\\n    Xc_te = char_vec.transform(test_texts)\\n\\n    X_tr = hstack([Xw_tr, Xc_tr]).tocsr()\\n    X_te = hstack([Xw_te, Xc_te]).tocsr()\\n    print(f\\'[INFO] Combined train features shape: {X_tr.shape}\\')\\n    print(f\\'[INFO] Combined test features shape: {X_te.shape}\\')\\n\\n    return X_tr, X_te\\n\\n\\ndef cv_select_and_train(X, y, seed=42):\\n    # Simple CV over a small grid of C values for LogisticRegression\\n    Cs = [0.25, 0.5, 1.0, 2.0, 4.0]\\n    best_auc = -1.0\\n    best_C = None\\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\\n\\n    print(\\'[INFO] Starting 5-fold CV to select C...\\')\\n    for C in Cs:\\n        aucs = []\\n        for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), start=1):\\n            X_tr, X_va = X[tr_idx], X[va_idx]\\n            y_tr, y_va = y[tr_idx], y[va_idx]\\n            clf = LogisticRegression(\\n                C=C,\\n                solver=\\'liblinear\\',\\n                class_weight=\\'balanced\\',\\n                max_iter=1000,\\n                n_jobs=1,\\n            )\\n            clf.fit(X_tr, y_tr)\\n            probs = clf.predict_proba(X_va)[:, 1]\\n            auc = roc_auc_score(y_va, probs)\\n            aucs.append(auc)\\n            print(f\\'  [CV] C={C} fold={fold} AUC={auc:.5f}\\')\\n        mean_auc = float(np.mean(aucs))\\n        print(f\\'[CV] C={C} mean AUC={mean_auc:.5f}\\')\\n        if mean_auc > best_auc:\\n            best_auc = mean_auc\\n            best_C = C\\n    print(f\\'[INFO] Best C={best_C} with CV AUC={best_auc:.5f}\\')\\n\\n    # Train final model on full data with best C\\n    final_clf = LogisticRegression(\\n        C=best_C,\\n        solver=\\'liblinear\\',\\n        class_weight=\\'balanced\\',\\n        max_iter=1000,\\n        n_jobs=1,\\n    )\\n    print(\\'[INFO] Training final model on full training data...\\')\\n    final_clf.fit(X, y)\\n    return final_clf, best_C, best_auc\\n\\n\\ndef main():\\n    t0 = time.time()\\n    # Paths\\n    data_dir = \\'/root/data\\'\\n    train_path = os.path.join(data_dir, \\'train.csv\\')\\n    test_path = os.path.join(data_dir, \\'test.csv\\')\\n    out_path = \\'/workspace/submission.csv\\'\\n\\n    # Load data\\n    print(\\'[INFO] Loading datasets...\\')\\n    train_df = pd.read_csv(train_path)\\n    test_df = pd.read_csv(test_path)\\n    print(f\\'[INFO] Train shape: {train_df.shape}  Test shape: {test_df.shape}\\')\\n\\n    # Extract fields\\n    y = train_df[\\'Insult\\'].astype(int).values\\n    raw_train_texts = train_df[\\'Comment\\']\\n    raw_test_texts = test_df[\\'Comment\\']\\n\\n    # Preprocess texts\\n    print(\\'[INFO] Preprocessing texts...\\')\\n    train_texts = preprocess_text_series(raw_train_texts)\\n    test_texts = preprocess_text_series(raw_test_texts)\\n\\n    # Build features\\n    X_tr, X_te = build_features(train_texts, test_texts)\\n\\n    # CV and train\\n    model, best_C, cv_auc = cv_select_and_train(X_tr, y)\\n\\n    # Predict\\n    print(\\'[INFO] Predicting probabilities on test set...\\')\\n    test_probs = model.predict_proba(X_te)[:, 1]\\n    test_probs = np.clip(test_probs, 0.0, 1.0)\\n\\n    # Compose submission: predictions in first column, then Date, Comment copied from test\\n    print(\\'[INFO] Writing submission to /workspace/submission.csv ...\\')\\n    sub_df = pd.DataFrame({\\n        \\'Insult\\': test_probs,\\n        \\'Date\\': test_df[\\'Date\\'],\\n        \\'Comment\\': test_df[\\'Comment\\'],\\n    })\\n    # Ensure directory exists\\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\\n    sub_df.to_csv(out_path, index=False)\\n\\n    dt = time.time() - t0\\n    print(f\\'[INFO] Done. Wrote {out_path}. Total time: {dt/60.0:.2f} min\\')\\n    print(f\\'[INFO] CV best C={best_C}, CV AUC={cv_auc:.5f}\\')\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trj.iloc[0][\"rollouts\"][0][\"traj\"][\"transitions\"][-1][\"info\"][\"pred_solution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4800, 9)\n",
      "Columns: ['task_name', 'task_description', 'code', 'percentile', 'valid_submission', 'eval_error_message', 'eval_duration', 'rollout_duration', 'rollout']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_description</th>\n",
       "      <th>code</th>\n",
       "      <th>percentile</th>\n",
       "      <th>valid_submission</th>\n",
       "      <th>eval_error_message</th>\n",
       "      <th>eval_duration</th>\n",
       "      <th>rollout_duration</th>\n",
       "      <th>rollout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detecting-insults-in-social-commentary</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...</td>\n",
       "      <td>import os\\nimport sys\\nimport time\\nimport pan...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Valid submission: percentile=1.0, execution_ti...</td>\n",
       "      <td>6.030760</td>\n",
       "      <td>232.229871</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaf-classification</td>\n",
       "      <td># Overview\\n\\n## Description\\nThere are estima...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.718672</td>\n",
       "      <td>True</td>\n",
       "      <td>Valid submission: percentile=0.718671679197995...</td>\n",
       "      <td>6.031679</td>\n",
       "      <td>239.587325</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detecting-insults-in-social-commentary</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Valid submission: percentile=1.0, execution_ti...</td>\n",
       "      <td>5.326396</td>\n",
       "      <td>264.277526</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nomad2018-predict-transparent-conductors</td>\n",
       "      <td># Overview\\n\\n## Description\\n\\nInnovative mat...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>0.898180</td>\n",
       "      <td>True</td>\n",
       "      <td>Valid submission: percentile=0.898179749715585...</td>\n",
       "      <td>14.303391</td>\n",
       "      <td>265.535683</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detecting-insults-in-social-commentary</td>\n",
       "      <td># Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...</td>\n",
       "      <td>#!/usr/bin/env python3\\nimport os\\nimport sys\\...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Valid submission: percentile=1.0, execution_ti...</td>\n",
       "      <td>12.928361</td>\n",
       "      <td>280.709331</td>\n",
       "      <td>[{'turn_id': 0, 'action': '', 'observation': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  task_name  \\\n",
       "0    detecting-insults-in-social-commentary   \n",
       "1                       leaf-classification   \n",
       "2    detecting-insults-in-social-commentary   \n",
       "3  nomad2018-predict-transparent-conductors   \n",
       "4    detecting-insults-in-social-commentary   \n",
       "\n",
       "                                    task_description  \\\n",
       "0  # Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...   \n",
       "1  # Overview\\n\\n## Description\\nThere are estima...   \n",
       "2  # Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...   \n",
       "3  # Overview\\n\\n## Description\\n\\nInnovative mat...   \n",
       "4  # Overview\\n\\n## Overview\\n\\n### Prizes\\n\\n###...   \n",
       "\n",
       "                                                code  percentile  \\\n",
       "0  import os\\nimport sys\\nimport time\\nimport pan...    1.000000   \n",
       "1  #!/usr/bin/env python3\\nimport os\\nimport sys\\...    0.718672   \n",
       "2  #!/usr/bin/env python3\\nimport os\\nimport sys\\...    1.000000   \n",
       "3  #!/usr/bin/env python3\\nimport os\\nimport sys\\...    0.898180   \n",
       "4  #!/usr/bin/env python3\\nimport os\\nimport sys\\...    1.000000   \n",
       "\n",
       "   valid_submission                                 eval_error_message  \\\n",
       "0              True  Valid submission: percentile=1.0, execution_ti...   \n",
       "1              True  Valid submission: percentile=0.718671679197995...   \n",
       "2              True  Valid submission: percentile=1.0, execution_ti...   \n",
       "3              True  Valid submission: percentile=0.898179749715585...   \n",
       "4              True  Valid submission: percentile=1.0, execution_ti...   \n",
       "\n",
       "   eval_duration  rollout_duration  \\\n",
       "0       6.030760        232.229871   \n",
       "1       6.031679        239.587325   \n",
       "2       5.326396        264.277526   \n",
       "3      14.303391        265.535683   \n",
       "4      12.928361        280.709331   \n",
       "\n",
       "                                             rollout  \n",
       "0  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "1  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "2  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "3  [{'turn_id': 0, 'action': '', 'observation': '...  \n",
       "4  [{'turn_id': 0, 'action': '', 'observation': '...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Flatten the dataframe\n",
    "df_flat = flatten_dataframe(df_trj)\n",
    "\n",
    "print(f\"Shape: {df_flat.shape}\")\n",
    "print(f\"Columns: {df_flat.columns.tolist()}\")\n",
    "df_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab197fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4800 rows to /checkpoint/maui_sft/winnieyangwn/amaia_dumps/514/trajectories/514_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "save_path = f'/checkpoint/maui_sft/winnieyangwn/amaia_dumps/{run_id}/trajectories/{run_id}_metadata.jsonl'\n",
    "\n",
    "# Save df_flat to jsonl\n",
    "df_flat.to_json(save_path, orient='records', lines=True)\n",
    "print(f\"Saved {len(df_flat)} rows to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204df1",
   "metadata": {},
   "source": [
    "# Data Structure Description\n",
    "\n",
    "The context is a list of dictionaries, where each dictionary represents one MLE Bench rollout (an agent's attempt to solve a machine learning task). There are 4,800 rollouts in total.\n",
    "\n",
    "Each rollout dictionary has the following fields:\n",
    "\n",
    "1. **\"task_name\"** (str): The unique identifier for the ML task (e.g., \"detecting-insults-in-social-commentary\")\n",
    "\n",
    "2. **\"task_description\"** (str): Full markdown description of the ML task including overview, evaluation criteria, and submission format\n",
    "\n",
    "3. **\"code\"** (str | None): The final Python code solution submitted by the agent\n",
    "\n",
    "4. **\"percentile\"** (float | None): Performance percentile (0-100) achieved by the submission. Higher is better. 100 means top performer.\n",
    "\n",
    "5. **\"valid_submission\"** (bool | None): Whether the agent produced a valid submission file\n",
    "\n",
    "6. **\"eval_error_message\"** (str | None): Evaluation result message - contains success info or error details\n",
    "\n",
    "7. **\"eval_duration\"** (float | None): GPU execution time in seconds for evaluation\n",
    "\n",
    "8. **\"rollout_duration\"** (float | None): Total time in seconds for the entire rollout\n",
    "\n",
    "9. **\"rollout\"** (list[dict]): The full conversation trajectory as a list of turns. Each turn has:\n",
    "   - \"turn_id\" (int): Turn number starting from 0\n",
    "   - \"action\" (str): The agent's action/response (typically bash commands in XML tags)\n",
    "   - \"observation\" (str): The environment's response/prompt to the agent\n",
    "\n",
    "## Example access patterns:\n",
    "```python\n",
    "# Get task name\n",
    "context[0][\"task_name\"]\n",
    "\n",
    "# Get percentile\n",
    "context[0][\"percentile\"]\n",
    "\n",
    "# Get number of turns\n",
    "len(context[0][\"rollout\"])\n",
    "\n",
    "# Get first action\n",
    "context[0][\"rollout\"][0][\"action\"]\n",
    "\n",
    "# Filter successful submissions\n",
    "[r for r in context if r[\"valid_submission\"] == True]\n",
    "\n",
    "# Filter by percentile\n",
    "[r for r in context if r[\"percentile\"] and r[\"percentile\"] >= 50]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cb64c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f6ba64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b705f4ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6df7c6f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c09749",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amaia-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
